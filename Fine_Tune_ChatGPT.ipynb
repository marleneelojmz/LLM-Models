{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Data Formatting"
      ],
      "metadata": {
        "id": "_fKPUFQWkJJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "import json\n",
        "from time import sleep\n",
        "import openai\n",
        "\n",
        "DEFAULT_SYSTEM_PROMPT = 'You are customer support bot. You should help to user to answer on his question.'\n",
        "\n",
        "def get_example(question, answer):\n",
        "    return {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": DEFAULT_SYSTEM_PROMPT},\n",
        "            {\"role\": \"user\", \"content\": question},\n",
        "            {\"role\": \"assistant\", \"content\": answer},\n",
        "        ]\n",
        "    }\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    df = pd.read_csv(\"dataset.csv\")\n",
        "    with open(\"train.jsonl\", \"w\") as f:\n",
        "        for i, row in list(df.iterrows()):\n",
        "            question = row[\"question\"]\n",
        "            answer = row[\"answer\"]\n",
        "            example = get_example(question, answer)\n",
        "            example_str = json.dumps(example)\n",
        "            f.write(example_str + \"\\n\")"
      ],
      "metadata": {
        "id": "dz73WY8JOD_n"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train your model"
      ],
      "metadata": {
        "id": "KSUYhugAkPor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKf0I4K-kglk",
        "outputId": "f60a65ef-4c7c-4e1d-eb76-3437518e22fd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " openai.api_key = \"<YOUR API KEY HERE>\""
      ],
      "metadata": {
        "id": "fcG9LmnloYy3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wait_untill_done(job_id):\n",
        "    events = {}\n",
        "    while True:\n",
        "        response = openai.FineTuningJob.list_events(id=job_id, limit=10)\n",
        "        # collect all events\n",
        "        for event in response[\"data\"]:\n",
        "            if \"data\" in event and event[\"data\"]:\n",
        "                events[event[\"data\"][\"step\"]] = event[\"data\"][\"train_loss\"]\n",
        "        messages = [it[\"message\"] for it in response.data]\n",
        "        for m in messages:\n",
        "            if m.startswith(\"New fine-tuned model created: \"):\n",
        "                return m.split(\"created: \")[1], events\n",
        "        sleep(10)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    response = openai.File.create(file=open(\"train.jsonl\", \"rb\"), purpose=\"fine-tune\")\n",
        "    uploaded_id = response.id\n",
        "    print(\"Dataset is uploaded\")\n",
        "    print(\"Sleep 30 seconds...\")\n",
        "    sleep(30)  # wait until dataset would be prepared\n",
        "    response = openai.FineTuningJob.create(training_file=uploaded_id,model=\"gpt-3.5-turbo\")\n",
        "    print(\"Fine-tune job is started\")\n",
        "    ft_job_id = response.id\n",
        "    new_model_name, events = wait_untill_done(ft_job_id)\n",
        "    with open(\"new_model_name.txt\", \"w\") as fp:\n",
        "        fp.write(new_model_name)\n",
        "    print(new_model_name)"
      ],
      "metadata": {
        "id": "23L6j3n5ObYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use your fine-tunned Model"
      ],
      "metadata": {
        "id": "kaYpE6nWt-fV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DEFAULT_SYSTEM_PROMPT ='You are customer support bot. You should help to user to answer on his question.'\n",
        "\n",
        "def get_fine_tuned_model_name():\n",
        "    with open(\"new_model_name.txt\") as fp:\n",
        "        return fp.read()\n",
        "\n",
        "def call_openai(model_name, messages):\n",
        "    response=openai.ChatCompletion.create(\n",
        "        messages=messages,\n",
        "        model=model_name\n",
        "    )\n",
        "    return response.choices[0][\"message\"][\"content\"]\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    model_name = get_fine_tuned_model_name()\n",
        "    history = [\n",
        "            {\"role\": \"system\", \"content\": DEFAULT_SYSTEM_PROMPT},\n",
        "        ]\n",
        "    while True:\n",
        "        user_input = input(\"User: \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            print(\"AI: Goodbye!\")\n",
        "            break\n",
        "        history.append({'role': 'user', 'content': user_input})\n",
        "        response = call_openai(model_name, history)\n",
        "        print(\"AI:\", response)\n",
        "        history.append({'role': :'assistant', 'content': response})"
      ],
      "metadata": {
        "id": "LhpTPjWlttC1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}